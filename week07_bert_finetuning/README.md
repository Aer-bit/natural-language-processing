How to fine-tune BERT:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/girafe-ai/natural-language-processing/blob/master/week07_bert_finetuning/bert_finetuning.ipynb)


__Further readings__:
* [Blog post](http://mccormickml.com/2019/07/22/BERT-fine-tuning/) about the aforementioned notebook

* The Illustrated BERT [blog post](http://jalammar.github.io/illustrated-bert/)

* DistillBERT overview (distillation will be covered later in our course) [blog post](https://medium.com/huggingface/distilbert-8cf3380435b5)

* Google AI Blog [post about open sourcing BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)

* One more [blog post explaining BERT](https://yashuseth.blog/2019/06/12/bert-explained-faqs-understand-bert-working/)

* Great PyTorch library: [pytorch-transformers](https://github.com/huggingface/transformers)
